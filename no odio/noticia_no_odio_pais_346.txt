Un sistema de visión artificial para vigilar los estragos de la guerra desde el espacio
######
Un equipo de investigadores desarrolla una herramienta que identifica en apenas unas horas los daños causados en las ciudades por los conflictos bélicos, un proceso clave para planificar la reconstrucción
######
Las ciudades del presente no están pensadas para la guerra. Atrás quedan fortificaciones y sistemas de murallas pensados para resistir un asedio. Sin embargo, los núcleos urbanos son ahora más que nunca objetivos bélicos, por su importancia política y económica y por la población que concentran. La estrategia no es nueva: “Los romanos destruyeron Cartago con fuego; Guernica, Coventry y Dresden sufrieron nuevas formas de combate siglos después ―bombardeo desde aviones militares―, e Hiroshima y Nagasaki sintieron los devastadores efectos que las armas nucleares desataron sobre ellas”, escribe Daniel Palmieri, investigador de Cruz Roja Internacional. Según datos de la misma entidad, 50 millones de personas sufren ahora las consecuencias de las guerras que golpean escenarios urbanos.Con un 56,5% de la población mundial viviendo en estos núcleos, monitorizar los estragos que la guerra deja en ellos se vuelve una tarea primordial en tareas como el despliegue de ayuda humanitaria, la vigilancia de los derechos humanos y la planificación de iniciativas de reconstrucción. “Es difícil verificar de forma independiente lo que está pasando, y eso crea un vacío de datos”, señala Andre Groeger, investigador de la Universidad Autónoma de Barcelona (UAB). Para suplir esas carencias un equipo del que forma parte Groeger ha desarrollado un sistema de visión artificial capaz de identificar la destrucción que causa la guerra sobre edificios de núcleos urbanos.“Si un barrio ha sido atacado, puedes determinar que cuanto mayor sea la destrucción de infraestructuras, más probable será que la gente lo abandone. Esto podría ayudar a ACNUR a prepararse para recibir flujos de refugiados”, ejemplifica el experto. Con él han colaborado Hannes Mueller, investigador del Instituto de Análisis Económico del CSIC; Jonathan Hersh y Andrea Matranga, de Chapman University, y Joan Serrat, de la UAB.“Las imágenes satelitales nocturnas se han utilizado mucho para usar la intensidad de la luz como medida del Producto Interior Bruto”, comenta el investigador. La alta resolución y la disponibilidad de imágenes históricas en portales de fácil acceso como Google Earth fueron clave en la puesta en marcha del proyecto, que ha dado como resultado una herramienta entrenada con fotos de núcleos urbanos afectados por la guerra en Siria y capaz de identificar por sí misma las áreas donde los edificios muestran daños causados por la artillería, bloques derrumbados o cráteres de bombas.Cuando no median máquinas, estas tareas de reconocimiento se ven obstaculizadas por la escasez de los datos sobre las zonas en conflicto y su baja calidad. La recopilación se complica además por la excesiva dependencia de la información que publican los medios y lo que reportan testigos. En tales condiciones, entidades como Amnistía Internacional o el Banco Mundial se ven obligadas a revisar manualmente las imágenes satelitales para poder obtener evaluaciones de los daños suficientemente precisas. De acuerdo con las estimaciones de los investigadores, etiquetar manualmente un conjunto de datos como el que han podido procesar en este proyecto tendría un coste de unos 200.000 dólares (unos 169.000 euros).Para entrenar el sistema de aprendizaje automático capaz de hacer la identificación automática de los edificios destruidos, los investigadores valoraron la posibilidad de crear su propio conjunto de datos de imágenes con las zonas dañadas ya identificadas. “Pero no lográbamos avanzar, porque no teníamos suficiente gente para recopilar esos datos”, recuerda Groeger. Los datos de otras fuentes de destrucción tampoco resultan útiles en estos casos, explica: “En un terremoto, por ejemplo, ves barrios enteros completamente destruidos. Un bombardeo destruye edificios aquí y allá”. Por último, recurrieron a Unosat, una agencia de la ONU que integra una unidad de desarrollo de aplicaciones con información satelital donde estas imágenes se etiquetan manualmente.Una vez entrenada la herramienta, la idea es que esta pueda seguir mejorando sus predicciones aprovechando incluso los mismos datos que genera. “Una vez que está entrenado suficientemente bien, el algoritmo puede asumir parte del trabajo humano que se hace en entidades como las Naciones Unidas y acelerar y abaratar la elaboración de estas evaluaciones”, añade el experto. Según estima Groeger, procesar y etiquetar un nuevo conjunto de imágenes con el sistema que han desarrollado es cuestión de un par de horas. “Si se hiciera manualmente estaríamos hablando de días o semanas”.El equipo ha seguido en contacto con Unosat, donde se han mostrado interesados en conocer más detalles del proyecto. “Estamos viendo cómo podríamos colaborar y llevar esta ida a una nueva fase”, matiza el investigador. Para el futuro, confían en que la utilización de nuevas bases de datos para el entrenamiento mejore los resultados y la sensibilidad del sistema en el registro de daños moderados. Avances como estos permitirían además ampliar la cobertura del sistema, que ahora mismo está especializado en el entorno de Siria e incluso aplicar el mismo procedimiento al proceso inverso y monitorizar la recuperación del territorio una vez concluido el conflicto.La información derivada de estos análisis permitiría conocer mejor los efectos de estos ataques desde el punto de vista social, identificar posibles sesgos en los métodos de reconocimiento tradicionales y responder a preguntas como en qué fases del conflicto se recurre a estas estrategias, qué puede hacerse para reducir las víctimas civiles o cuál es el efecto de la destrucción de edificios sobre el desplazamiento de la población, comparado con otros tipos de violencia, como el uso de pequeñas armas de fuego.
######
Montse Hidalgo Pérez
######
06 jul 2021-03:20 UTC